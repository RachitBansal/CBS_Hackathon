{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackCBS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachitBansal/CBS_Hackathon/blob/master/HackCBS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-twSSBXt312y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snCikJgQ8tAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c635a009-209f-4b83-e613-9a2140a5d6e3"
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 5692498.04B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vTL88NG8gEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"Here is the sentence I want embeddings for.\"\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrIAqJHk9P-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-mj47ik-AGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw5nCaxaAZp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_i = 0\n",
        "batch_i = 0\n",
        "token_i = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QCHCAG4-wlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6304d51b-4276-4bd2-a796-661083283ed4"
      },
      "source": [
        "token_embeddings = [] \n",
        "\n",
        "# For each token in the sentence...\n",
        "for token_i in range(len(tokenized_text)):\n",
        "  \n",
        "  # Holds 12 layers of hidden states for each token \n",
        "  hidden_layers = [] \n",
        "  \n",
        "  # For each of the 12 layers...\n",
        "  for layer_i in range(len(encoded_layers)):\n",
        "    \n",
        "    # Lookup the vector for `token_i` in `layer_i`\n",
        "    vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "    \n",
        "    hidden_layers.append(vec)\n",
        "    \n",
        "  token_embeddings.append(hidden_layers)\n",
        "\n",
        "# Sanity check the dimensions:\n",
        "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
        "print (\"Number of layers per token:\", len(token_embeddings[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens in sequence: 22\n",
            "Number of layers per token: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHJH1UlGiVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5zpH0LrGy7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_YdZKvXnsZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78bb1d44-f989-4cbe-9bab-66603001fcec"
      },
      "source": [
        "sent = [\"I am Jeevesh Juneja . \"]\n",
        "embedding = model.encode(sent)\n",
        "print(len(embedding))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apfxqiJHTPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b8f42c1d-6300-4e61-f69b-a2c392a91468"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.cluster.vq\n",
        "renew_sentences = ['I want to renew my policy . ', 'I want my policy renewed as soon as possible', 'How can i get my policy renewed?']\n",
        "new_sentences = ['I want to get a new policy.',\"I read about your new policy and now i can't wait to get it\",\"I came across this new policy of yours about cars, can i get it?\"]\n",
        "check_sentences = ['How soon can i renew my policy?' , 'I read about this accident in the news, i was a victim there , can i get the new policy']\n",
        "corpus = renew_sentences + new_sentences + check_sentences\n",
        "corpus_embeddings = model.encode(corpus)\n",
        "embeddings = []\n",
        "for embedding in corpus_embeddings :\n",
        "  embeddings.append(np.array(embedding))\n",
        "print(np.dot(embeddings[6],embeddings[0])+np.dot(embeddings[6],embeddings[1])+np.dot(embeddings[6],embeddings[2]))\n",
        "print(np.dot(embeddings[7],embeddings[0])+np.dot(embeddings[7],embeddings[1])+np.dot(embeddings[7],embeddings[2]))\n",
        "print(np.dot(embeddings[6],embeddings[3])+np.dot(embeddings[6],embeddings[4])+np.dot(embeddings[6],embeddings[5]))\n",
        "print(np.dot(embeddings[7],embeddings[3])+np.dot(embeddings[7],embeddings[4])+np.dot(embeddings[7],embeddings[5]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "674.24854\n",
            "238.70427\n",
            "488.1926\n",
            "326.747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4OiEE6Whyqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests \n",
        "\n",
        "URL = '54.173.118.186/accounts/login'\n",
        "\n",
        "data = { 'username' : ''\n",
        "         'password' : ''\n",
        "         'otp' : ''\n",
        "         'businesstype' : ''}\n",
        "r = requests.post( url=URL, data=data )\n",
        "\n",
        "r = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whe3KhcrxCl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "info_we_have = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXC-uMOJ7pbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kit_details = ['status', 'discrepant reason', 'purchase date', 'sold value', 'sold by', 'duration', 'distributor', 'store', 'payment']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ibS3SBHZZlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_similarity(sentence, features) :\n",
        "  sentence_embeddings = model.encode(sentence)\n",
        "  feature_embeddings = model.encode(feature)\n",
        "  lis = []\n",
        "  for feature in feature_embeddings :\n",
        "    lis.append(np.dot(sentence_embeddings[0],feature))\n",
        "  i = lis.index(max(lis))\n",
        "  lis = sort(lis)\n",
        "  print(lis[0:5])\n",
        "  return features[i]  #Or return list of features accoding to some threshold\n",
        "\n",
        "def update_feature(s, val) :\n",
        "  info_we_have[s] = val\n",
        "\n",
        "def get_feature(s) :\n",
        "  if s in info_we_have.keys() :\n",
        "    return info_we_have[s]\n",
        "\n",
        "def kit_particular_details(sentence) :\n",
        "  lis = get_max_similarity(sentence, kit_details)\n",
        "  i = get_feature('kit_id') \n",
        "  kit = requests.get('23.22.237.185/zopperassure/kit/'+str(i))\n",
        "  kit_details = kit.json()\n",
        "  for feature in lis :\n",
        "    print(feature)\n",
        "    print(kit_details[feature])\n",
        "\n",
        "def warranty_particular_details(sentence) :\n",
        "  lis = get_max_similarity(sentence, warranty_details)\n",
        "  i = get_feature('kit_id') \n",
        "  kit = requests.get('23.22.237.185/zopperassure/kit/'+str(i))\n",
        "  kit_details = kit.json()\n",
        "  for feature in lis :\n",
        "    print(feature)\n",
        "    print(kit_details[feature])\n",
        "\n",
        "def store_info(key,value) :\n",
        "\n",
        "def create_warranty() :\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXW09AcCY3oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "warranty_creation = []#sentences asking to create new warranty\n",
        "kit_details = ['status','What is the status of my kit?','discrepant reason']#sentences asking to get kit details\n",
        "warranty_details = []#sentences asking to get warranty details\n",
        "submit_claim = []#sentences asking for submitting a claim\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}